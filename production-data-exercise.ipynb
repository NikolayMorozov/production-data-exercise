{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production analysis exercise\n",
    "\n",
    "## Import libraries\n",
    "\n",
    "Pandas and basic matplotlib visualization should be sufficient to complete the exercise. Feel free to use any other libraries/modules to complete the tasks\n",
    "\n",
    "Replace `<TO DO>`'s with your code, please. If you wish to add code outsides of existing `<TO DO>` please feel free to do so.\n",
    "Clean and well-commented code is highly appreciated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as py\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the links to the input datasets located in aws s3 bucket\n",
    " - s3://advisor.energy-data-exercise/Headers.csv\n",
    " - s3://advisor.energy-data-exercise/Monthly Production.csv\n",
    " - s3://advisor.energy-data-exercise/Trajectories.csv\n",
    "\n",
    "You can either read data directly from s3 or download files first and read them form your local storage by using  aws cli command `aws s3 cp s3://advisor.energy-data-exercise/Headers.csv Headers.csv --no-sign-request`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data here\n",
    "header = <TO DO>\n",
    "production = <TO DO>\n",
    "trajectories = <TO DO>\n",
    "\n",
    "print(type(header), type(production), type(trajectories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output summary (columns, row count) for each of the three datasets below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#header data set\n",
    "\n",
    "header_row_count = <TO DO>\n",
    "header_columns = <TO DO>\n",
    "\n",
    "print(header_row_count, len(header_columns), header_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#production\n",
    "\n",
    "production_row_count = <TO DO>\n",
    "production_columns = <TO DO>\n",
    "\n",
    "print(production_row_count, len(production_columns), production_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trajectories\n",
    "\n",
    "trajectories_row_count = <TO DO>\n",
    "trajectories_columns = <TO DO>\n",
    "\n",
    "print(trajectories_row_count, len(trajectories_columns), trajectories_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let look at following data pieces\n",
    "`API14` column form `header`,\n",
    "`API/UWI` columns from `monthly production`, and\n",
    "`API Number` column from `trajectories`\n",
    "\n",
    "All those tree columns meant to be the unique id that can be used to merge datasets. Apart from the obvious discrepancy in columns names. The `API Number` has only 12 digits while the other two have 14 digits format. Next task is to fix `API Number` by adding two zeros to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix `API Number` here\n",
    "\n",
    "<TO DO>\n",
    "\n",
    "# sample same a single API form all three datasets, to make sure thay are identical\n",
    "header_api = <TO DO>\n",
    "production_api = <TO DO>\n",
    "header_api = <TO DO>\n",
    "\n",
    "print(header_api==production_api==header_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter datasets and limit them to contain records that corresponds to \n",
    "`Operator Company Name (Beta)` from `header` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter datasets below\n",
    "\n",
    "header = <TO DO>\n",
    "production = <TO DO>\n",
    "trajectories = <TO DO>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization and analysis\n",
    " - Scatter plot of 2D projections of well trajectories (Scatterplot of Latitude, Longitude \n",
    "columns form trajectories dataset)\n",
    " - color-coded the scatter plot by `First 6 BOE` column form `header`. You would need to merge together trajectories and `first 6 BOE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge Latitude, Longetude and `first 6 BOE`\n",
    "\n",
    "<TO DO>\n",
    "\n",
    "x = <TO DO>\n",
    "y = <TO DO>\n",
    "c = <TO DO>\n",
    "\n",
    "py.scatter(x=x,y=y,c=c, marker = 'o', cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production wedge analysis\n",
    "\n",
    "Let's create two separate wedge production plots for each of the two selected operators OXY and Noble\n",
    " - Build yearly benches. Essentially it is a table that contains a mapping of `well id` and a `year` each well started its production\n",
    " - Calculate Equivalent monthly production. Create a new column `\"Equivalent, boe\"` in `monthly production` dataset (`\"Equivalent, boe\" = \"Monthly Oil\" + \"Monthly Gas\" / 6`)\n",
    "\n",
    "Resulting plots shoul look simmilar to (there is a Bench.png next to notebook file, just in case it doesn't show below)\n",
    "<img src=\"files/Bench.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build yearly_mapping \n",
    "#  it should have to columns well ip (API) and year (year of first production)\n",
    "\n",
    "yearly_mapping = <TO DO>\n",
    "\n",
    "yearly_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there is a need to create a separate plot for each of the operators, \n",
    "it is rational to wrap this piece as a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_bench_dataset(<TO DO>):\n",
    "    '''\n",
    "    Transform aggregates and pivots input data sets and yearly benches time series\n",
    "    Inputs\n",
    "     - data\n",
    "     - operators name\n",
    "    Outputs\n",
    "      - pandas dataframe where index is monthly dates, and columns yearly benches (2010, 2011, \n",
    "      ..., 2018) alternatively you will handle visualization yourself \n",
    "    '''\n",
    "    \n",
    "    return <TO DO>\n",
    "\n",
    "# OXY bench plot\n",
    "form_bench_dataset(<TO DO>).plot.area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nobel bench plot\n",
    "form_bench_dataset(<TO DO>).plot.area()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional exercise\n",
    "Forecast each bench production through the end of 2025.\n",
    " - you might do it on individual wells forecast and then aggregate into benches or preform forecast for benches themselves\n",
    " - keep forecast on monthly resolution time wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<TO DO>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
